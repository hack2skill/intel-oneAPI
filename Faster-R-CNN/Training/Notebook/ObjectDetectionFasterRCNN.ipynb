{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import necessary libraries for linear algebra, data processing, file I/O, image processing, machine learning, and visualization.**"
      ],
      "metadata": {
        "id": "9JdDajG4yqIE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0et2FUFFMusl"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install the torchvision library.**"
      ],
      "metadata": {
        "id": "NsPKFQlDywG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwTm5AZ5M6Ob",
        "outputId": "60c02570-b6cd-48fd-ef24-09c3cbe075d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import the required modules from torch and torchvision libraries.**"
      ],
      "metadata": {
        "id": "KNVlG4d1y2ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "from torchvision.transforms import functional as FT\n",
        "from torchvision import transforms as T\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, sampler, random_split, Dataset\n",
        "import copy\n",
        "import math\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as A  # our data augmentation library\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "oXyMIKI4M6Xk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from collections import defaultdict, deque\n",
        "import datetime\n",
        "import time\n",
        "from tqdm import tqdm # progress bar\n",
        "from torchvision.utils import draw_bounding_boxes"
      ],
      "metadata": {
        "id": "w03Uxk0PM-QF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3cpi7NJM_8u",
        "outputId": "8bddb0aa-2b94-4744-9305-86031c7d4ec4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "0.15.2+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install the pycocotools library.**\n",
        "Import the required modules from pycocotools library."
      ],
      "metadata": {
        "id": "pkd4uCe4zFL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# our dataset is in cocoformat, we will need pypcoco tools\n",
        "!pip install pycocotools\n",
        "from pycocotools.coco import COCO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITeEaw0LNC3s",
        "outputId": "6671fd7a-fbc7-4dcf-eb90-88f852847c9a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import the required module from the `'albumentations.pytorch'` library.**"
      ],
      "metadata": {
        "id": "bmodTdBBzQpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we will define our transforms\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "metadata": {
        "id": "3W60HO1lNFFP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define a function get_transforms that returns the data augmentation transforms based on whether it's for training or not.**"
      ],
      "metadata": {
        "id": "-y_KnTV0zZ92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms(train=False):\n",
        "    if train:\n",
        "        transform = A.Compose([\n",
        "            A.Resize(600, 600), # our input size can be 600px\n",
        "            A.HorizontalFlip(p=0.3),\n",
        "            A.VerticalFlip(p=0.3),\n",
        "            A.RandomBrightnessContrast(p=0.1),\n",
        "            A.ColorJitter(p=0.1),\n",
        "            ToTensorV2()\n",
        "        ], bbox_params=A.BboxParams(format='coco'))\n",
        "    else:\n",
        "        transform = A.Compose([\n",
        "            A.Resize(600, 600), # our input size can be 600px\n",
        "            ToTensorV2()\n",
        "        ], bbox_params=A.BboxParams(format='coco'))\n",
        "    return transform"
      ],
      "metadata": {
        "id": "SOaWdW_bNG_8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define a class `'ObjectDetection'` that inherits from `'datasets.VisionDataset'` This class represents an object detection dataset.**"
      ],
      "metadata": {
        "id": "tjSa3pgNzdpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ObjectDetection(datasets.VisionDataset):\n",
        "    def __init__(self, root, split='train', transform=None, target_transform=None, transforms=None):\n",
        "        # the 3 transform parameters are reuqired for datasets.VisionDataset\n",
        "        super().__init__(root, transforms, transform, target_transform)\n",
        "        self.split = split #train, valid, test\n",
        "        self.coco = COCO(os.path.join(root, split, \"_annotations.coco.json\")) # annotatiosn stored here\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "        self.ids = [id for id in self.ids if (len(self._load_target(id)) > 0)]\n",
        "    \n",
        "    def _load_image(self, id: int):\n",
        "        path = self.coco.loadImgs(id)[0]['file_name']\n",
        "        image = cv2.imread(os.path.join(self.root, self.split, path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        return image\n",
        "    def _load_target(self, id):\n",
        "        return self.coco.loadAnns(self.coco.getAnnIds(id))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        id = self.ids[index]\n",
        "        image = self._load_image(id)\n",
        "        target = self._load_target(id)\n",
        "        target = copy.deepcopy(self._load_target(id))\n",
        "        \n",
        "        boxes = [t['bbox'] + [t['category_id']] for t in target] # required annotation format for albumentations\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, bboxes=boxes)\n",
        "        \n",
        "        image = transformed['image']\n",
        "        boxes = transformed['bboxes']\n",
        "        \n",
        "        new_boxes = [] # convert from xywh to xyxy\n",
        "        for box in boxes:\n",
        "            xmin = box[0]\n",
        "            xmax = xmin + box[2]\n",
        "            ymin = box[1]\n",
        "            ymax = ymin + box[3]\n",
        "            new_boxes.append([xmin, ymin, xmax, ymax])\n",
        "        \n",
        "        boxes = torch.tensor(new_boxes, dtype=torch.float32)\n",
        "        \n",
        "        targ = {} # here is our transformed target\n",
        "        targ['boxes'] = boxes\n",
        "        targ['labels'] = torch.tensor([t['category_id'] for t in target], dtype=torch.int64)\n",
        "        targ['image_id'] = torch.tensor([t['image_id'] for t in target])\n",
        "        targ['area'] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) # we have a different area\n",
        "        targ['iscrowd'] = torch.tensor([t['iscrowd'] for t in target], dtype=torch.int64)\n",
        "        return image.div(255), targ # scale images\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ],
      "metadata": {
        "id": "Y6KNyEtJNJF9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install the roboflow library**\n",
        "\n",
        "Import the `'Roboflow'` class from the `'roboflow'` library and login to Roboflow. Set up the Roboflow workspace, project, and dataset to download."
      ],
      "metadata": {
        "id": "TgNd0DxG0L3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "import roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "roboflow.login()\n",
        "rf = Roboflow()\n",
        "project = rf.workspace(\"ympublic\").project(\"bdd-kcbst\")\n",
        "dataset = project.version(2).download(\"coco\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7NrJXO_0NLoA",
        "outputId": "6781fc39-87b2-41b8-fe77-55361c36a216"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.0.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Collecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (8.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.15)\n",
            "Collecting wget (from roboflow)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.39.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (2.0.12)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=2a3672ac6ea275a92722fa131cad9de6752f1b7bc4fe599a7f6c79b08469cc77\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-dotenv, pyparsing, idna, cycler, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "Successfully installed cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.0.9 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "idna",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rvisit https://app.roboflow.com/auth-cli to get your authentication token.\n",
            "Paste the authentication token here: ··········\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in bdd-2 to coco: 100% [697584956 / 697584956] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to bdd-2 in coco:: 100%|██████████| 8001/8001 [00:04<00:00, 1885.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Specify the path to the dataset**"
      ],
      "metadata": {
        "id": "kiBoh_TO0q7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/bdd-2\""
      ],
      "metadata": {
        "id": "P5gVdaG3N-bl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the COCO annotations and get the categories**"
      ],
      "metadata": {
        "id": "79zogb0w0wSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load classes\n",
        "import os\n",
        "coco = COCO(os.path.join(dataset_path, \"train\", \"_annotations.coco.json\"))\n",
        "categories = coco.cats\n",
        "n_classes = len(categories.keys())\n",
        "categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5ZC0HcyOIpN",
        "outputId": "ce45e5df-2dde-4d48-c939-98e4e2e9c34a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.96s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'id': 0, 'name': 'obj', 'supercategory': 'none'},\n",
              " 1: {'id': 1, 'name': 'bike', 'supercategory': 'obj'},\n",
              " 2: {'id': 2, 'name': 'bus', 'supercategory': 'obj'},\n",
              " 3: {'id': 3, 'name': 'car', 'supercategory': 'obj'},\n",
              " 4: {'id': 4, 'name': 'motor', 'supercategory': 'obj'},\n",
              " 5: {'id': 5, 'name': 'person', 'supercategory': 'obj'},\n",
              " 6: {'id': 6, 'name': 'rider', 'supercategory': 'obj'},\n",
              " 7: {'id': 7, 'name': 'traffic light', 'supercategory': 'obj'},\n",
              " 8: {'id': 8, 'name': 'traffic sign', 'supercategory': 'obj'},\n",
              " 9: {'id': 9, 'name': 'train', 'supercategory': 'obj'},\n",
              " 10: {'id': 10, 'name': 'truck', 'supercategory': 'obj'}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create an instance of the `ObjectDetection` class for the train dataset**"
      ],
      "metadata": {
        "id": "_ZciI8dK0210"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ObjectDetection(root=dataset_path, transforms=get_transforms(True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koej1arSOXaj",
        "outputId": "c8aa83b6-10ab-4b93-ced8-aec86c03d5e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.59s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Print the length of the train dataset**"
      ],
      "metadata": {
        "id": "n7brZrp00_uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_ARu6jeOZkf",
        "outputId": "4bd26444-0f5f-4d69-9043-4efb44016989"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7537"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the Faster R-CNN model**\n",
        "\n",
        "Get the input features of the model and replace the box predictor with a new one that matches the number of classes."
      ],
      "metadata": {
        "id": "Rh6DHL5r1FAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets load the faster rcnn model\n",
        "model = models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features # we need to change the head\n",
        "model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QrgcyPnObtu",
        "outputId": "465a5c9b-de91-4370-a792-c782b3fcd89a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\n",
            "100%|██████████| 74.2M/74.2M [00:00<00:00, 191MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define a collate function to process the batch data**"
      ],
      "metadata": {
        "id": "OYmhD7Sm1QbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "lrZpWSr9OdtE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create a data loader for the train dataset**"
      ],
      "metadata": {
        "id": "hbg4FjXq1VP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "nyLDhRGjOfsh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get a batch of images and targets from the data loader**"
      ],
      "metadata": {
        "id": "5dfAvFfx1fYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images,targets = next(iter(train_loader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k:v for k, v in t.items()} for t in targets]\n",
        "output = model(images, targets) # just make sure this runs without error"
      ],
      "metadata": {
        "id": "ZpIPxQG6Oi7b"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Move the model to the CUDA device**"
      ],
      "metadata": {
        "id": "OgFKRkO71hQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "BJ7KeaLEOjBU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Hw8r4DLJOok0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set up the optimizer for training**"
      ],
      "metadata": {
        "id": "CqHE_wh_1p7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, and optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, nesterov=True, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "kW8Q6M9oOq6U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "93VJ12RQOuKX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define a function `train_one_epoch` to train the model for one epoch**"
      ],
      "metadata": {
        "id": "dQaZl_431uaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, loader, device, epoch):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    \n",
        "#     lr_scheduler = None\n",
        "#     if epoch == 0:\n",
        "#         warmup_factor = 1.0 / 1000 # do lr warmup\n",
        "#         warmup_iters = min(1000, len(loader) - 1)\n",
        "        \n",
        "#         lr_scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor = warmup_factor, total_iters=warmup_iters)\n",
        "    \n",
        "    all_losses = []\n",
        "    all_losses_dict = []\n",
        "    \n",
        "    for images, targets in tqdm(loader):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n",
        "        \n",
        "        loss_dict = model(images, targets) # the model computes the loss automatically if we pass in targets\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_dict_append = {k: v.item() for k, v in loss_dict.items()}\n",
        "        loss_value = losses.item()\n",
        "        \n",
        "        all_losses.append(loss_value)\n",
        "        all_losses_dict.append(loss_dict_append)\n",
        "        \n",
        "        if not math.isfinite(loss_value):\n",
        "            print(f\"Loss is {loss_value}, stopping trainig\") # train if loss becomes infinity\n",
        "            print(loss_dict)\n",
        "            sys.exit(1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "#         if lr_scheduler is not None:\n",
        "#             lr_scheduler.step() # \n",
        "        \n",
        "    all_losses_dict = pd.DataFrame(all_losses_dict) # for printing\n",
        "    print(\"Epoch {}, lr: {:.6f}, loss: {:.6f}, loss_classifier: {:.6f}, loss_box: {:.6f}, loss_rpn_box: {:.6f}, loss_object: {:.6f}\".format(\n",
        "        epoch, optimizer.param_groups[0]['lr'], np.mean(all_losses),\n",
        "        all_losses_dict['loss_classifier'].mean(),\n",
        "        all_losses_dict['loss_box_reg'].mean(),\n",
        "        all_losses_dict['loss_rpn_box_reg'].mean(),\n",
        "        all_losses_dict['loss_objectness'].mean()\n",
        "    ))"
      ],
      "metadata": {
        "id": "G8_M4o26Ow6b"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Specify the number of epochs**\n",
        "\n",
        "Train the model for the specified number of epochs"
      ],
      "metadata": {
        "id": "q6FzXoFh127R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=25\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
        "#     lr_scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ7QpJ8nOzX4",
        "outputId": "b93dbdf2-5846-4ae8-cd63-6090c55cabf7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:43<00:00,  1.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, lr: 0.010000, loss: 0.789628, loss_classifier: 0.294390, loss_box: 0.330234, loss_rpn_box: 0.092803, loss_object: 0.072201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:43<00:00,  1.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, lr: 0.010000, loss: 0.696107, loss_classifier: 0.250047, loss_box: 0.300715, loss_rpn_box: 0.085371, loss_object: 0.059973\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:43<00:00,  1.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, lr: 0.010000, loss: 0.668316, loss_classifier: 0.239408, loss_box: 0.291297, loss_rpn_box: 0.082661, loss_object: 0.054951\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:41<00:00,  1.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, lr: 0.010000, loss: 0.653712, loss_classifier: 0.232904, loss_box: 0.288116, loss_rpn_box: 0.080392, loss_object: 0.052300\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:38<00:00,  1.39it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, lr: 0.010000, loss: 0.636142, loss_classifier: 0.225887, loss_box: 0.281950, loss_rpn_box: 0.078544, loss_object: 0.049762\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:40<00:00,  1.39it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, lr: 0.010000, loss: 0.626703, loss_classifier: 0.222280, loss_box: 0.280297, loss_rpn_box: 0.077080, loss_object: 0.047045\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:40<00:00,  1.39it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, lr: 0.010000, loss: 0.616674, loss_classifier: 0.217373, loss_box: 0.276954, loss_rpn_box: 0.076138, loss_object: 0.046209\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:38<00:00,  1.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, lr: 0.010000, loss: 0.606650, loss_classifier: 0.213673, loss_box: 0.273497, loss_rpn_box: 0.074922, loss_object: 0.044558\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:36<00:00,  1.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, lr: 0.010000, loss: 0.603609, loss_classifier: 0.212177, loss_box: 0.274170, loss_rpn_box: 0.074024, loss_object: 0.043238\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:36<00:00,  1.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, lr: 0.010000, loss: 0.596401, loss_classifier: 0.209145, loss_box: 0.272556, loss_rpn_box: 0.072870, loss_object: 0.041830\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:34<00:00,  1.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, lr: 0.010000, loss: 0.592103, loss_classifier: 0.207613, loss_box: 0.271842, loss_rpn_box: 0.071933, loss_object: 0.040715\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:35<00:00,  1.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, lr: 0.010000, loss: 0.587415, loss_classifier: 0.204998, loss_box: 0.271069, loss_rpn_box: 0.071380, loss_object: 0.039967\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:34<00:00,  1.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, lr: 0.010000, loss: 0.584437, loss_classifier: 0.203877, loss_box: 0.270956, loss_rpn_box: 0.070645, loss_object: 0.038960\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:33<00:00,  1.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, lr: 0.010000, loss: 0.581550, loss_classifier: 0.203259, loss_box: 0.270895, loss_rpn_box: 0.069577, loss_object: 0.037818\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:31<00:00,  1.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, lr: 0.010000, loss: 0.577053, loss_classifier: 0.201367, loss_box: 0.269361, loss_rpn_box: 0.068793, loss_object: 0.037532\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:31<00:00,  1.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, lr: 0.010000, loss: 0.572541, loss_classifier: 0.199027, loss_box: 0.268477, loss_rpn_box: 0.068374, loss_object: 0.036663\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:30<00:00,  1.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, lr: 0.010000, loss: 0.570490, loss_classifier: 0.198553, loss_box: 0.268745, loss_rpn_box: 0.067348, loss_object: 0.035843\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:29<00:00,  1.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, lr: 0.010000, loss: 0.572367, loss_classifier: 0.198517, loss_box: 0.271685, loss_rpn_box: 0.067027, loss_object: 0.035138\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:31<00:00,  1.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, lr: 0.010000, loss: 0.577836, loss_classifier: 0.201289, loss_box: 0.273218, loss_rpn_box: 0.067484, loss_object: 0.035845\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:28<00:00,  1.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, lr: 0.010000, loss: 0.567463, loss_classifier: 0.196836, loss_box: 0.270578, loss_rpn_box: 0.066130, loss_object: 0.033918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:26<00:00,  1.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, lr: 0.010000, loss: 0.563924, loss_classifier: 0.195704, loss_box: 0.269648, loss_rpn_box: 0.065373, loss_object: 0.033198\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 472/472 [05:20<00:00,  1.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21, lr: 0.010000, loss: 0.562074, loss_classifier: 0.194527, loss_box: 0.269728, loss_rpn_box: 0.064834, loss_object: 0.032985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 472/472 [05:20<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, lr: 0.010000, loss: 0.560396, loss_classifier: 0.194317, loss_box: 0.269646, loss_rpn_box: 0.064108, loss_object: 0.032325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 472/472 [05:20<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, lr: 0.010000, loss: 0.560158, loss_classifier: 0.194185, loss_box: 0.269584, loss_rpn_box: 0.064268, loss_object: 0.032121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 472/472 [05:20<00:00,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, lr: 0.010000, loss: 0.559255, loss_classifier: 0.193716, loss_box: 0.269879, loss_rpn_box: 0.063747, loss_object: 0.031913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set the model to evaluation mode and clear the GPU cache**"
      ],
      "metadata": {
        "id": "Dyu5mjlK2AFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "IG6JEQawyBvM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save the trained model to a file**"
      ],
      "metadata": {
        "id": "LGEbtlos2FQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/model.pth')"
      ],
      "metadata": {
        "id": "NnPGDvKKwR-6"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}