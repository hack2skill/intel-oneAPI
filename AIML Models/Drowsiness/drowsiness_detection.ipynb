{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import face_recognition\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearnex.model_selection import train_test_split\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout\n",
        "import numpy as np\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "65m3Xc9l-EnO"
      },
      "outputs": [],
      "source": [
        "def eye_cropper(image_path):\n",
        "    frame = cv2.imread(image_path)  # Read the image using OpenCV\n",
        "    if frame is None:\n",
        "        return None\n",
        "    \n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "    facial_features_list = face_recognition.face_landmarks(gray)\n",
        "\n",
        "    try:\n",
        "        eye = facial_features_list[0]['left_eye']\n",
        "    except:\n",
        "        try:\n",
        "            eye = facial_features_list[0]['right_eye']\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    x_max = max([coordinate[0] for coordinate in eye])\n",
        "    x_min = min([coordinate[0] for coordinate in eye])\n",
        "    y_max = max([coordinate[1] for coordinate in eye])\n",
        "    y_min = min([coordinate[1] for coordinate in eye])\n",
        "\n",
        "    x_range = x_max - x_min\n",
        "    y_range = y_max - y_min\n",
        "\n",
        "    if x_range > y_range:\n",
        "        right = round(.5 * x_range) + x_max\n",
        "        left = x_min - round(.5 * x_range)\n",
        "        bottom = round((((right - left) - y_range)) / 2) + y_max\n",
        "        top = y_min - round((((right - left) - y_range)) / 2)\n",
        "    else:\n",
        "        bottom = round(.5 * y_range) + y_max\n",
        "        top = y_min - round(.5 * y_range)\n",
        "        right = round((((bottom - top) - x_range)) / 2) + x_max\n",
        "        left = x_min - round((((bottom - top) - x_range)) / 2)\n",
        "\n",
        "    cropped = frame[top:(bottom + 1), left:(right + 1)]\n",
        "\n",
        "    cropped = cv2.resize(cropped, (80, 80))\n",
        "    image_for_prediction = cropped.reshape(-1, 80, 80, 3)\n",
        "\n",
        "    return image_for_prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l62ZfgOZAStH",
        "outputId": "5567b08a-99f9-40d6-c52e-98d8da2c5a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Succesful Image Import Count = 500\n",
            "Succesful Image Import Count = 1000\n",
            "Succesful Image Import Count = 1500\n",
            "Succesful Image Import Count = 2000\n",
            "Succesful Image Import Count = 500\n",
            "Succesful Image Import Count = 1000\n",
            "Succesful Image Import Count = 1500\n",
            "Succesful Image Import Count = 2000\n"
          ]
        }
      ],
      "source": [
        "def load_images_from_folder(folder, eyes = 0):\n",
        "    count = 0\n",
        "    error_count = 0\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        try:\n",
        "            img = cv2.imread(os.path.join(folder,filename))\n",
        "            img = cv2.resize(img, (80,80)) ## Resizing the images\n",
        "            ## for eyes if it is 0: open, 1: close\n",
        "            images.append([img, eyes])\n",
        "        except:\n",
        "            error_count += 1\n",
        "            print('ErrorCount = ' + str(error_count))\n",
        "            continue\n",
        "        \n",
        "        count += 1\n",
        "        if count % 500 == 0:\n",
        "            print('Succesful Image Import Count = ' + str(count))\n",
        "\n",
        "    return images\n",
        "\n",
        "folder=\"./dataset/Open_Eyes\"\n",
        "open_eyes = load_images_from_folder(folder, 0)\n",
        "\n",
        "folder=\"./dataset/Closed_Eyes\"\n",
        "closed_eyes = load_images_from_folder(folder, 1)\n",
        "eyes = closed_eyes + open_eyes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m5K0wji8ASwi"
      },
      "outputs": [],
      "source": [
        "X = [] \n",
        "y = [] \n",
        "for features, label in eyes: \n",
        "     X.append(features)\n",
        "     y.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7n5urpYl_Ofl"
      },
      "outputs": [],
      "source": [
        "X = np.array(X).reshape(-1, 80, 80, 3)\n",
        "y = np.array(y)\n",
        "X = X/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eZs28CEQ_Oiu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZXKRwY7_Ol0",
        "outputId": "3b546b97-631c-48cf-de99-b6dc12c95013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/24\n",
            "94/94 [==============================] - 12s 110ms/step - loss: 0.3843 - auc: 0.8985 - val_loss: 0.1402 - val_auc: 0.9846\n",
            "Epoch 2/24\n",
            "94/94 [==============================] - 10s 105ms/step - loss: 0.1122 - auc: 0.9874 - val_loss: 0.0736 - val_auc: 0.9963\n",
            "Epoch 3/24\n",
            "94/94 [==============================] - 10s 107ms/step - loss: 0.0658 - auc: 0.9962 - val_loss: 0.0315 - val_auc: 0.9986\n",
            "Epoch 4/24\n",
            "94/94 [==============================] - 10s 107ms/step - loss: 0.0776 - auc: 0.9940 - val_loss: 0.0570 - val_auc: 0.9989\n",
            "Epoch 5/24\n",
            "94/94 [==============================] - 10s 107ms/step - loss: 0.0448 - auc: 0.9971 - val_loss: 0.0686 - val_auc: 0.9896\n",
            "Epoch 6/24\n",
            "94/94 [==============================] - 10s 108ms/step - loss: 0.0417 - auc: 0.9986 - val_loss: 0.0394 - val_auc: 0.9961\n",
            "Epoch 7/24\n",
            "94/94 [==============================] - 10s 108ms/step - loss: 0.0160 - auc: 0.9991 - val_loss: 0.0208 - val_auc: 0.9972\n",
            "Epoch 8/24\n",
            "94/94 [==============================] - 10s 110ms/step - loss: 0.0131 - auc: 0.9998 - val_loss: 0.0237 - val_auc: 0.9979\n",
            "Epoch 9/24\n",
            "94/94 [==============================] - 10s 111ms/step - loss: 0.0109 - auc: 0.9992 - val_loss: 0.0271 - val_auc: 0.9979\n",
            "Epoch 10/24\n",
            "94/94 [==============================] - 10s 111ms/step - loss: 0.0050 - auc: 0.9993 - val_loss: 0.0326 - val_auc: 0.9939\n",
            "Epoch 11/24\n",
            "94/94 [==============================] - 10s 110ms/step - loss: 0.0241 - auc: 0.9985 - val_loss: 0.0179 - val_auc: 0.9979\n",
            "Epoch 12/24\n",
            "94/94 [==============================] - 10s 111ms/step - loss: 0.0015 - auc: 1.0000 - val_loss: 0.0290 - val_auc: 0.9980\n",
            "Epoch 13/24\n",
            "94/94 [==============================] - 11s 115ms/step - loss: 0.0011 - auc: 1.0000 - val_loss: 0.0211 - val_auc: 0.9980\n",
            "Epoch 14/24\n",
            "94/94 [==============================] - 11s 117ms/step - loss: 4.5868e-04 - auc: 1.0000 - val_loss: 0.0234 - val_auc: 0.9980\n",
            "Epoch 15/24\n",
            "94/94 [==============================] - 11s 119ms/step - loss: 0.0315 - auc: 0.9978 - val_loss: 0.0272 - val_auc: 0.9976\n",
            "Epoch 16/24\n",
            "94/94 [==============================] - 11s 115ms/step - loss: 0.0350 - auc: 0.9963 - val_loss: 0.0168 - val_auc: 0.9977\n",
            "Epoch 17/24\n",
            "94/94 [==============================] - 10s 111ms/step - loss: 0.0220 - auc: 0.9982 - val_loss: 0.0326 - val_auc: 0.9978\n",
            "Epoch 18/24\n",
            "94/94 [==============================] - 10s 111ms/step - loss: 0.0259 - auc: 0.9988 - val_loss: 0.0218 - val_auc: 0.9979\n",
            "Epoch 19/24\n",
            "94/94 [==============================] - 10s 111ms/step - loss: 0.0157 - auc: 0.9992 - val_loss: 0.0116 - val_auc: 0.9999\n",
            "Epoch 20/24\n",
            "94/94 [==============================] - 11s 113ms/step - loss: 0.0011 - auc: 1.0000 - val_loss: 0.0026 - val_auc: 1.0000\n",
            "Epoch 21/24\n",
            "94/94 [==============================] - 10s 110ms/step - loss: 0.0979 - auc: 0.9925 - val_loss: 0.0607 - val_auc: 0.9979\n",
            "Epoch 22/24\n",
            "94/94 [==============================] - 10s 110ms/step - loss: 0.0258 - auc: 0.9983 - val_loss: 0.0227 - val_auc: 0.9978\n",
            "Epoch 23/24\n",
            "94/94 [==============================] - 10s 111ms/step - loss: 0.0055 - auc: 1.0000 - val_loss: 0.0083 - val_auc: 1.0000\n",
            "Epoch 24/24\n",
            "94/94 [==============================] - 10s 112ms/step - loss: 0.0035 - auc: 1.0000 - val_loss: 0.0079 - val_auc: 1.0000\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.0079 - auc: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.007898536510765553, 0.9999880194664001]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Adding first three convolutional layers\n",
        "model.add(Conv2D(\n",
        "                filters = 32, # number of filters\n",
        "                kernel_size = (3,3), # height/width of filter\n",
        "                activation = 'relu', # activation function \n",
        "                input_shape = (80,80,3) # shape of input (image)\n",
        "                ))\n",
        "model.add(Conv2D(\n",
        "                filters = 32, # number of filters\n",
        "                kernel_size = (3,3), # height/width of filter\n",
        "                activation = 'relu' # activation function \n",
        "                ))\n",
        "model.add(Conv2D(\n",
        "                filters = 32, # number of filters\n",
        "                kernel_size = (3,3), # height/width of filter\n",
        "                activation = 'relu' # activation function \n",
        "                ))\n",
        "\n",
        "# Adding pooling after convolutional layers\n",
        "model.add(MaxPooling2D(pool_size = (2,2))) # Dimensions of the region that you are pooling\n",
        "\n",
        "# Adding second set of convolutional layers\n",
        "model.add(Conv2D(\n",
        "                filters = 32, # number of filters\n",
        "                kernel_size = (3,3), # height/width of filter\n",
        "                activation = 'relu' # activation function \n",
        "                ))\n",
        "model.add(Conv2D(\n",
        "                filters = 32, # number of filters\n",
        "                kernel_size = (3,3), # height/width of filter\n",
        "                activation = 'relu' # activation function \n",
        "                ))\n",
        "\n",
        "# Add last pooling layer.\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# Adding first dense layer with 256 nodes\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Adding a dropout layer to avoid overfitting\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3)) \n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# adding output layer\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "# compiling the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=[tf.keras.metrics.AUC(curve = 'PR')])\n",
        "\n",
        "start = time()\n",
        "# fitting the model\n",
        "model.fit(X_train,\n",
        "            y_train,\n",
        "            batch_size=32,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=24)\n",
        "end = time()\n",
        "\n",
        "# evaluate the model \n",
        "model.evaluate(X_test, y_test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WjPNx8nO_Opc"
      },
      "outputs": [],
      "source": [
        "model.save('./dataset/drowsiness_detection.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_responce(image, model):    \n",
        "    image_for_prediction = eye_cropper(image)\n",
        "    if image_for_prediction is None:\n",
        "        return 'Yes'\n",
        "    try:\n",
        "        image_for_prediction = image_for_prediction/255.0\n",
        "    except:\n",
        "        print(\"Error\")\n",
        "    \n",
        "    prediction = model.predict(image_for_prediction)\n",
        "    print(prediction)\n",
        "    # Based on prediction, display either \"Open Eyes\" or \"Closed Eyes\"\n",
        "    if prediction < 0.7:\n",
        "        status = 'No'\n",
        "    else:\n",
        "        status = 'Yes'\n",
        "    return status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = model_responce(image, model) #input image here\n",
        "print(_)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
